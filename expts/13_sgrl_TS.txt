train.train_one_epoch_fn.loss_wts.feat=1.0
train.train_one_epoch_fn.loss_wts.past_cls_action=0.1
train.train_one_epoch_fn.loss_wts.global_simContrast=0.0
train.train_one_epoch_fn.loss_wts.past_target_global_simContrast=0.0
train.init_from_model=[[backbone.model,${cwd}/DATA/pretrained/TIMM/jx_vit_base_patch16_224_in21k-e5005f0a.pth]]

pre_train_path=${cwd}/OUTPUTS/expts/13_sgrl_TS_init.txt/0/checkpoint.pth
pre_train=true 

train.batch_size=2
eval.batch_size=2
train.num_epochs=10

+model.detector=false
+model.detector_dim=2048
+model.freeze_detector=false
+model.pretrained_detector=false
+model.pretrained_detector_weights=${cwd}/DATA/pretrained/TIMM/res_obj_det.pth

model.freeze_weights=true
model/backbone=avt_b_in21k
model.backbone_last_n_modules_to_drop=0
model.backbone_dim=768
model/temporal_aggregator=identity
model/future_predictor=avth
model.dropout=0.8
+model.future_predictor.n_head=8
+model.future_predictor.n_layer=8
+model.future_predictor.output_len=1
+model.future_predictor.inter_dim=2048
+model.future_predictor.return_past_too=true
+model.future_predictor.future_pred_loss={_target_: torch.nn.MSELoss}
+model.future_predictor.avg_last_n=1
model.classifier_on_past=true


opt.lr_wd=[[__all__,0.0000005,0.0001]]
opt.bias_bn_wd_scale=1.0
# opt.optimizer.nesterov=true

data_train.num_frames=10
data_train.frame_rate=0.5
data_train.subclips.num_frames=1
data_train.subclips.stride=1
data_eval.num_frames=${data_train.num_frames}
data_eval.frame_rate=${data_train.frame_rate}
data_eval.subclips.num_frames=${data_train.subclips.num_frames}
data_eval.subclips.stride=${data_train.subclips.stride}
data_train.mean=[0.5, 0.5, 0.5]
data_train.std=[0.5, 0.5, 0.5]
data_eval.mean=${data_train.mean}
data_eval.std=${data_train.std}
data_eval.eval_num_crops=3
data_eval.eval_flip_crops=true

opt/optimizer=adam
opt/scheduler=cosine
opt.warmup.num_epochs=10

dataset/dundee50salads/annot_reader_fn=abu_farha
dataset.dundee50salads.common.fold=1,2,3,4,5
dataset@dataset_train=dundee50salads/anticipation_train
dataset@dataset_eval=dundee50salads/anticipation_val
dataset_train.sample_strategy=last_clip
dataset_eval.sample_strategy=last_clip
dataset_train.conv_to_anticipate_fn.tau_o=20
dataset_eval.conv_to_anticipate_fn.tau_o=20

+dataset_train.conv_to_anticipate_fn.drop_style=correct
+dataset_eval.conv_to_anticipate_fn.drop_style=correct

data_train.scale_h=248-280
data_train.scale_w=-1
data_train.crop_size=224
data_eval.scale_h=248
data_eval.scale_w=-1
data_eval.crop_size=224

hydra.launcher.nodes=4
hydra.launcher.gpus_per_node=8